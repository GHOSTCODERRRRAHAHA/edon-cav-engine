# Why EDON Can Perform Worse in Zero-Shot Mode

## Quick Answer

**EDON wasn't trained on MuJoCo**, so it's making decisions based on a different environment. Sometimes those decisions are wrong for MuJoCo's specific dynamics.

---

## Root Causes

### 1. **Wrong Strategy Selection** üéØ

EDON selects one of 4 strategies:
- **NORMAL**: Standard control
- **HIGH_DAMPING**: Reduces action magnitude (more conservative)
- **RECOVERY_BALANCE**: Aggressive corrections
- **COMPLIANT_TERRAIN**: Adjusts for uneven terrain

**Problem:** The policy network was trained on `MockHumanoidEnv` (simplified dynamics), but MuJoCo has:
- Full rigid-body physics
- Different contact dynamics
- Different inertia properties
- Different joint limits

**Result:** EDON might select HIGH_DAMPING when it should select RECOVERY_BALANCE, or vice versa.

**Example:**
```
MuJoCo scenario: Robot tilting, needs aggressive correction
EDON thinks: "This looks stable, use NORMAL strategy" ‚ùå
Should be: "This needs RECOVERY_BALANCE strategy" ‚úÖ
```

### 2. **Wrong Modulation Values** üìä

EDON outputs modulations:
- `gain_scale` (0.5-2.0): Scales entire action
- `lateral_compliance` (0.0-1.0): Reduces lateral movement
- `step_height_bias` (-1 to 1): Adjusts step height

**Problem:** These values were learned for the training environment, not MuJoCo.

**Example:**
```
MuJoCo needs: gain_scale=1.2 (slightly more aggressive)
EDON outputs: gain_scale=0.7 (too conservative) ‚ùå
Result: Robot doesn't correct fast enough ‚Üí more interventions
```

### 3. **Environment Mismatch** üîÑ

**Training Environment (`MockHumanoidEnv`):**
- Simplified dynamics (direct roll/pitch/COM control)
- 4-element action space `[-1, 1]`
- Simple integration with damping
- No contact forces

**MuJoCo Environment:**
- Full rigid-body physics
- 12-element joint torques `[-20, 20]`
- Complex contact, friction, inertia
- Joint limits, damping, gear ratios

**Result:** EDON's learned responses don't always transfer well.

### 4. **Fail-Risk Prediction Errors** ‚ö†Ô∏è

EDON uses a fail-risk model to predict intervention probability.

**Problem:** The fail-risk model was trained on the original environment, so it might:
- Underestimate risk in MuJoCo (thinks it's safe when it's not)
- Overestimate risk (thinks it's dangerous when it's stable)
- Miss MuJoCo-specific failure modes

**Example:**
```
MuJoCo: Robot is actually stable (low risk)
Fail-risk model: Predicts high risk (0.8) ‚ùå
EDON: Applies aggressive corrections ‚Üí destabilizes robot
```

### 5. **Action Space Mismatch** üìê

**Training:** Actions in `[-1, 1]` range (normalized)
**MuJoCo:** Actions in `[-20, 20]` range (torques)

**Current fix:** We normalize MuJoCo actions to `[-1, 1]` before applying EDON, then scale back.

**But:** The mapping might not be perfect:
- Different action magnitudes mean different effects
- EDON's modulations might not scale correctly
- Joint-level control vs. abstract balance control

### 6. **Random Variation** üé≤

Even with the same disturbance script, small differences can cascade:
- Initial conditions (robot starting pose)
- Numerical precision
- Random noise in sensors/actuators
- Timing of EDON API calls

**Result:** Some runs are better, some are worse.

---

## Why Training Fixes This

### After Training on MuJoCo:

1. **Strategy Selection Learns MuJoCo:**
   - Policy learns: "In MuJoCo, when tilt > X, use RECOVERY_BALANCE"
   - Not guessing from a different environment

2. **Modulations Optimized for MuJoCo:**
   - Learns correct `gain_scale` for MuJoCo's dynamics
   - Learns correct `lateral_compliance` for MuJoCo's contact
   - Learns correct `step_height_bias` for MuJoCo's terrain

3. **Fail-Risk Model Retrained:**
   - Predicts MuJoCo-specific failure modes
   - Accurate risk assessment for MuJoCo

4. **Consistent Performance:**
   - 90%+ improvement (not variable)
   - Reliable across runs

---

## What You Can Do Now

### 1. **Run Multiple Times** (Get Average)
```bash
# Run 10 times, average the results
# This gives you true zero-shot performance
```

### 2. **Check EDON Strategy Selection**
Look at the UI's "EDON Control Info" panel:
- What strategy is EDON using?
- Is it appropriate for the situation?

### 3. **Check Modulations**
- `gain_scale`: Is it too high/low?
- `lateral_compliance`: Is it reducing necessary corrections?
- `intervention_risk`: Is fail-risk prediction accurate?

### 4. **Train on MuJoCo** (Best Solution)
```bash
python demo_mujoco/train_edon_mujoco.py --episodes 300
```
This will give you 90%+ consistent improvement.

---

## Summary

**Why EDON performs worse sometimes:**
1. ‚ùå Wrong strategy selection (trained on different environment)
2. ‚ùå Wrong modulation values (not optimized for MuJoCo)
3. ‚ùå Environment mismatch (simplified vs. full physics)
4. ‚ùå Fail-risk prediction errors (trained on different environment)
5. ‚ùå Action space mismatch (normalized vs. torques)
6. ‚ùå Random variation (inherent in zero-shot transfer)

**Solution:**
- ‚úÖ Train EDON on MuJoCo ‚Üí 90%+ consistent improvement
- ‚úÖ Or accept variability ‚Üí average multiple runs

**Bottom line:** Zero-shot transfer is impressive (25-66% improvement), but it's variable. Training eliminates the variability and gives consistent 90%+ improvement.

